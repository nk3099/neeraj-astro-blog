---
layout: ../../layouts/MarkdownPostLayout.astro
title: "MCP : Model Context Protocol"
publishedDate: 2025-05-04
description: "Learning about MCP"
author: "Nitish Kumar"
image:
  url: ""
  alt: "Learning about MCP"
tags: ["MCP", "Python", "learn-in-public","Gen-AI"]
featuredPost: True
---

> *â€œWhy did the AI cross the road? To call a function on the other sideâ€”with MCP!â€*

### ğŸ—‚ï¸ Table of Contents

1. [ğŸ›‹ï¸ Introduction](#ğŸ›‹ï¸-introduction)
2. [ğŸŒ‰ Bridging the Gap: Why MCP?](#ğŸŒ‰-bridging-the-gap-why-mcp)
3. [ğŸ¢ MCP Architecture: Who Talks to Whom?](#ğŸ¢-mcp-architecture-who-talks-to-whom)
4. [ğŸ› ï¸ MCP Primitives: Tools, Resources, Prompts](#ğŸ› ï¸-mcp-primitives-tools-resources-prompts)
5. [ğŸ”Œ Transport Mechanisms: Stdio vs. SSE](#ğŸ”Œ-transport-mechanisms-stdio-vs-sse)
6. [ğŸ§‘â€ğŸ’» My Implementations](#my-implementations)
    - [ğŸ“» 1. Stdio: The â€œWalkie-Talkieâ€ Approach](#ğŸ“»-1-stdio-the-walkie-talkie-approach)
    - [ğŸŒ 2. SSE: The â€œLong-Distance Relationshipâ€](#ğŸŒ-2-sse-the-long-distance-relationship)
    - [ğŸ¤– 3. LLM + Tools: The â€œSupercharged Chatbotâ€](#ğŸ¤–-3-llm--tools-the-supercharged-chatbot)
7. [ğŸ“ Practical Considerations: Should You MCP?](#ğŸ“-practical-considerations-should-you-mcp)
8. [ğŸ”‘ Key Takeaways](#ğŸ”‘-key-takeaways)
9. [ğŸ Conclusion: Is MCP for You?](#ğŸ-conclusion-is-mcp-for-you)
10. [ğŸ“š Further Reading](#ğŸ“š-further-reading)
11. [ğŸ”— References & Further Learning](#ğŸ”—-references--further-learning)

---

### ğŸ›‹ï¸ Introduction

Remember when you needed a different remote for every device in your living room? One for the TV, another for the sound system, and a third for that ancient DVD player you never use? It was chaosâ€”until the universal remote came along and saved the day.

The **Model Context Protocol (MCP)** is the universal remote for your AI tools. Itâ€™s the new kid on the AI block, and everyoneâ€™s buzzing about it. But is it a revolution, or just another fancy gadget? Spoiler: itâ€™s more like finally having one remote to rule them allâ€”no more juggling APIs for every tool!

If youâ€™ve ever wished your LLM could just â€œcall a friendâ€ (or a function) without learning a new language, MCP is your answer. Itâ€™s not magic, but it *is* a standardized way for LLMs to interact with external tools and services. By the end of this post, youâ€™ll know how to wire up your own AI tools with MCPâ€”and maybe even retire a few remotes of your own.

### ğŸŒ‰ Bridging the Gap: Why MCP?

Letâ€™s face it: AI agents are only as smart as the tools they can use. Imagine asking your AI to check the weather, only to get a blank stare (or worse, a hallucinated answer about â€œsunny with a chance of meatballsâ€). Frustrating, right?

MCP bridges the gap between your LLM and the outside worldâ€”whether thatâ€™s your local file system, a weather API, or your companyâ€™s HR database. Itâ€™s like giving your AI a phone and a contact list, so it can finally call the right people (or tools) when you need answers.

**Two main use cases:**
- **Personal Use:** Plug MCP into your favorite AI tools (Claude Desktop, IDEs, etc.).
- **Backend Integration:** Embed MCP into your Python apps and agent systems for seamless tool access. No more â€œSorry, I canâ€™t do thatâ€â€”your AI can finally get stuff done.

*Think of MCP as the â€œuniversal translatorâ€ for your AIâ€™s function-calling needs. No more language barriers between your LLM and the tools you love!*

### ğŸ¢ MCP Architecture: Who Talks to Whom?

Picture a busy office: you (the host) ask your assistant (the client) to fetch a file from the archives (the server). MCP formalizes this workflow:

- **MCP Hosts:** The â€œbossâ€ (Claude, IDEs, your app)
- **MCP Clients:** The â€œassistantâ€ (protocol client)
- **MCP Servers:** The â€œspecialistsâ€ (file server, web search server, etc.)
- **Local Data Sources:** The â€œarchivesâ€ (files, DBs)
- **Remote Services:** The â€œvendorsâ€ (APIs, external systems)

#### ğŸ§¬ Under the Hood: JSON-RPC 2.0

MCP messages are sent using the [JSON-RPC 2.0](https://www.jsonrpc.org/specification) protocolâ€”a lightweight, widely-used standard for remote procedure calls. This means your tools and LLMs can communicate in a predictable, language-agnostic way.

### ğŸ› ï¸ MCP Primitives: Tools, Resources, Prompts

- **Tools:** Like giving your LLM a Swiss Army knifeâ€”functions it can call (add numbers, fetch weather, etc.).
- **Resources:** The contextâ€”files, DB records, or anything your LLM might need to â€œread up on.â€
- **Prompts:** Templates for LLM interactions (think: Mad Libs for AI).

*ğŸ’¡ Pro tip: Start with tools. Theyâ€™re the easiest way to make your LLM actually â€œdoâ€ stuff!*

### ğŸ”Œ Transport Mechanisms: Stdio vs. SSE

#### ğŸ“» Stdio: The â€œWalkie-Talkieâ€ Approach

- **How it works:** Both client and server run locally, chatting over standard input/output.
- **When to use:** Local dev, quick prototyping, or when you donâ€™t want to deal with networks.
- **Analogy:** Like passing notes in classâ€”simple, direct, but you have to be in the same room.

#### ğŸŒ SSE: The â€œLong-Distance Relationshipâ€

- **How it works:** Client and server talk over HTTP and Server-Sent Events (SSE).
- **When to use:** When your client and server are on different machines, or you want to scale.
- **Analogy:** Like texting your friend across the worldâ€”reliable, works over the internet, but needs a little setup.

### ğŸ§‘â€ğŸ’» My Implementations

Letâ€™s get our hands dirty! Hereâ€™s how I actually used MCPâ€”warts, wins, and all.

#### ğŸ“» 1. Stdio: The â€œWalkie-Talkieâ€ Approach

This is the â€œhello worldâ€ of MCP. I started with the stdio transport because, letâ€™s be honest, who wants to debug network issues on day one?

**How I did it:**
- Ran `client-stdio.py` and `server.py` in the same terminal.
- The client asked the server what tools it had (spoiler: just an `add` function).
- I asked it to add 2 + 3. It obliged. Math class, but with robots.

**Sample logs:**
```
(crash-course) âœ  3-simple-server-setup git:(main) âœ— python3 client-stdio.py
[INFO] Processing request of type ListToolsRequest
Available tools:
  - add: Add two numbers together
[INFO] Processing request of type CallToolRequest
2 + 3 = 5
```

**Takeaway:**  
Great for local tinkering. Like using a calculator app, but you built the calculator.

#### ğŸŒ 2. SSE: The â€œLong-Distance Relationshipâ€

Once I got bored of talking to myself (and my computer), I tried the SSE transport. Now my client and server could live on different machinesâ€”like a distributed team, but with less coffee.

**How I did it:**
- Started the server: `python server.py` (it listened on port 8050).
- The client (`client-sse.py`) connected to `/sse` for real-time, streaming communication.
- FastMCP handled the HTTP/SSE magic behind the scenes.

**Sample logs:**
```
(crash-course) âœ  3-simple-server-setup git:(main) âœ— python server.py
Running server with SSE transport
INFO:     Uvicorn running on http://0.0.0.0:8050 (Press CTRL+C to quit)
[INFO] Processing request of type ListToolsRequest
[INFO] Processing request of type CallToolRequest
```
From the client:
```
(crash-course) âœ  3-simple-server-setup git:(main) âœ— python3 client-sse.py 
Available tools:
  - add: Add two numbers together
2 + 3 = 5
```

**Whatâ€™s really happening:**  
The client connects to `/sse`, the server streams responses (and â€œpingsâ€ to keep the line open). Itâ€™s like a walkie-talkie, but with WiFi.

#### ğŸ¤– 3. LLM + Tools: The â€œSupercharged Chatbotâ€ (RAG-style, No Vector DB)

Hereâ€™s where things get spicy. I wanted my LLM to be more than a parrotâ€”so I gave it tools and a knowledge base. No fancy vector DBs, just a humble `docs.json` file with Q&A pairs.

**How I did it:**
- The MCP server exposed a tool: `get_knowledge_base`, which returned all Q&A pairs as a formatted string.
- The client (an LLM, e.g., GroqLLM) got the userâ€™s question.
- The LLM decided: â€œDo I know this, or should I phone a friend (the tool)?â€
- If it called the tool, the server fetched the info and handed it back. The LLM then crafted a user-friendly answer.

**Sample logs:**
```
(crash-course) âœ  4-groq-integration git:(main) âœ— python3 client.py
[INFO] Processing request of type ListToolsRequest

Connected to server with tools:
  - get_knowledge_base: Retrieve the entire knowledge base as a formatted string.

Query: What is our company's vacation policy?
[INFO] Processing request of type ListToolsRequest
[INFO] Processing request of type CallToolRequest

Response: According to our company's knowledge base, full-time employees are entitled to 20 paid vacation days per year...
```

**Why this is cool:**  
- **MCP is the bridge**â€”the LLM can â€œphone a friendâ€ (tool) when it needs help.
- The LLM chooses when to use its own brain vs. external knowledge.
- Itâ€™s like RAG (Retrieval-Augmented Generation), but with a simple tool instead of a vector DB. Sometimes, simple is smart!

### ğŸ“ Practical Considerations: Should You MCP?

- **Donâ€™t fix what isnâ€™t broken:** If your current function-calling setup works, donâ€™t rush to MCP-ify everything.
- **Butâ€¦** If youâ€™re building new projects, or want to make your tools reusable and modular, MCP is a game-changer.
- **Start small:** Try stdio for local dev, then graduate to SSE when youâ€™re ready to go global.

### ğŸ”‘ Key Takeaways

- **MCP = Universal remote for your AI tools.**
- **Stdio:** Great for local dev and prototyping.
- **SSE:** Perfect for distributed, production-ready setups.
- **LLM + Tools:** Where the magic happensâ€”give your AI real superpowers.
- **Donâ€™t overcomplicate:** Sometimes a simple tool beats a fancy database.

### ğŸ Conclusion: Is MCP for You?

MCP isnâ€™t just another buzzwordâ€”itâ€™s a practical, powerful standard for making your LLMs actually *do* things. Whether youâ€™re building a personal AI assistant or a production-grade agent, MCP gives you the foundation for modular, reusable, and scalable integrations.

So next time your AI asks, â€œCan I phone a friend?â€â€”hand it the MCP manual and watch the magic happen. ğŸª„

### ğŸ“š Further Reading

**ğŸ”’ Security Tip:**  
- If youâ€™re exposing MCP endpoints, make sure to secure your JSON-RPC layer!  
- Check out my deep dive: [Securing JSON-RPC](https://nkumar37.vercel.app/posts/securing_json_rpc)

### ğŸ”— References & Further Learning

- [DeepLearning.AI - Model Context Protocol](https://learn.deeplearning.ai/courses/mcp-build-rich-context-ai-apps-with-anthropic/lesson/fkbhh/introduction)
- [MCP Crash Course](https://www.youtube.com/watch?v=5xqFjh56AwM)
- [MCP Krish Naik](https://www.youtube.com/watch?v=MDBG2MOp4Go)
- [My Github](https://github.com/iamheavymetalx7/learn-by-building/tree/rough-branch)